---
title: "Imputing Missing Values: Random Forest vs K-Nearest Neighbors"
author: Robert Adongo  
date: "June 7, 2025"
output:
  # cleanrmd::html_document_clean:
  #   theme: NULL
  #   toc: true
  #   toc_float: true
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    number_sections: true
    theme: flatly
    highlight: tango
    df_print: paged
    #css: "custom.css"
bibliography: references.bib
csl: apa.csl
link-citations: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction
## Motivation and Goals 
Missing data poses a significant barrier to effective analysis in many applied research domains. The K-Nearest Neighbors (KNN) method is a simple and widely used imputation technique [@troyanskaya2001missing]. In this project, we implement the `kNN` function from the `VIM` package, which is based on a variation of the Gower distance. This approach is suitable for handling numerical, categorical, ordered, and semi-continuous variables [@kowarik2016imputation].

We also utilize Random Forest (RF), a non-parametric ensemble method, for imputation. Specifically, we employ the `missForest` function from the `missForestPredict` package [@troyanskaya2001missing; @van2011mice; @stekhoven2012missforest; @wright2017ranger].

The goal of this document is to provide a theoretical background for the two imputation methods mentioned above, apply them to datasets with different structures and missingness patterns, and compare their performance.

## The `KNN` Function
`kNN(
  data,
  variable = colnames(data),
  metric = NULL,
  k = 5,
  dist_var = colnames(data),
  weights = NULL,
  numFun = median,
  catFun = maxCat,
  makeNA = NULL,
  NAcond = NULL,
  impNA = TRUE,
  donorcond = NULL,
  mixed = vector(),
  mixed.constant = NULL,
  trace = FALSE,
  imp_var = TRUE,
  imp_suffix = "imp",
  addRF = FALSE,
  onlyRF = FALSE,
  addRandom = FALSE,
  useImputedDist = TRUE,
  weightDist = FALSE,
  methodStand = "range",
  ordFun = medianSamp
)`

## The `missForest` Function
`missForest(
  xmis,
  maxiter = 10,
  fixed_maxiter = FALSE,
  var_weights = NULL,
  decreasing = FALSE,
  initialization = "mean/mode",
  x_init = NULL,
  class.weights = NULL,
  return_integer_as_integer = FALSE,
  save_models = TRUE,
  predictor_matrix = NULL,
  proportion_usable_cases = c(1, 0),
  verbose = TRUE,
  convergence_error = "OOB",
  ...
)`

# Mathematical Setup
## K Nearest Neighbor Imputation

### Model Form
The mathematical setup presented in this section is based on the work by Kowarik and Templ [@kowarik2016imputation], who provide a comprehensive formulation of k-nearest neighbor imputation as implemented in the `VIM` package.

Suppose we observe a data set with missing values. Let \( \mathbf{x}_i = (x_{i1}, x_{i2}, \dots, x_{ip}) \) represent the observed values for observation \( i \) across \( p \) variables, where some entries in \( \mathbf{x}_i \) may be missing.

The goal of k-nearest neighbor (kNN) imputation is to fill in the missing entries of \( \mathbf{x}_i \) using information from the **k most similar (complete) observations**.

Similarity between two observations \( \mathbf{x}_i \) and \( \mathbf{x}_j \) is measured by a **generalized Gower distance**, which is defined to accommodate numerical, categorical, ordinal, binary, and semi-continuous variables [@gower1971general].

### Generalized Gower Distance

Let \( d_{ij} \) denote the distance between observations \( i \) and \( j \). Then:

\[
d_{ij} = \frac{\sum_{k=1}^p w_k \delta_{ijk}}{\sum_{k=1}^p w_k}
\]

where:
 \( w_k \geq 0 \) is the weight assigned to variable \( k \),
 \( \delta_{ijk} \in [0, 1] \) measures the contribution of variable \( k \) to the overall distance between \( i \) and \( j \).

The form of \( \delta_{ijk} \) depends on the type of variable \( k \):

- **Continuous variables**:

\[
\delta_{ijk} = \frac{|x_{ik} - x_{jk}|}{r_k}, \quad \text{where } r_k = \max(x_{\cdot k}) - \min(x_{\cdot k})
\]

- **Ordinal variables** (converted to integers):

\[
\delta_{ijk} = \frac{|x_{ik} - x_{jk}|}{r_k}
\]

- **Nominal or binary variables**:

\[
\delta_{ijk} =
\begin{cases}
0, & \text{if } x_{ik} = x_{jk} \\
1, & \text{otherwise}
\end{cases}
\]

- **Semi-continuous variables** (e.g., income with many zeros):

\[
\delta_{ijk} =
\begin{cases}
0, & \text{if } x_{ik} = s_k \text{ and } x_{jk} = s_k \\
1, & \text{if exactly one of } x_{ik}, x_{jk} \text{ equals } s_k \\
\frac{|x_{ik} - x_{jk}|}{r_k}, & \text{if } x_{ik} \neq s_k \text{ and } x_{jk} \neq s_k
\end{cases}
\]

Here, \( s_k \) is the “special” value (typically zero) where the variable has mass.

### Aggregation Rule

Once the distances \( d_{ij} \) are computed, the **k nearest neighbors** of observation \( i \) (with complete data) are identified. The missing entries of \( \mathbf{x}_i \) are then imputed using an aggregation of the corresponding values from its neighbors:

- For **continuous variables**:

\[
\hat{x}_{ik} = \text{median}\left\{x_{jk} : j \in \mathcal{N}_k(i) \right\}
\]

- For **categorical variables**:

\[
\hat{x}_{ik} = \text{mode}\left\{x_{jk} : j \in \mathcal{N}_k(i) \right\}
\]

where \( \mathcal{N}_k(i) \) denotes the set of indices of the k nearest neighbors for observation \( i \) (based on distance in selected variables).

### Tuning Parameter \( k \)

The parameter \( k \in \mathbb{N} \) controls the number of nearest neighbors used in imputation. Small values of \( k \) may lead to high variance; large values may oversmooth or dilute local structure.

## Random Forest Imputation

The Random Forest-based imputation approach used in this study is based on the missForest algorithm introduced by Stekhoven and Bühlmann [@stekhoven2012missforest]. This method uses iterative, variable-wise Random Forest models to estimate missing entries in a mixed-type data matrix without relying on parametric assumptions.

---

### Data Structure and Objective

Let \( \mathbf{X} = (x_{ij}) \in \mathbb{R}^{n \times p} \) denote a data matrix with \( n \) observations and \( p \) variables. Some entries in \( \mathbf{X} \) are missing.

For each variable \( j \in \{1, \dots, p\} \), define
\( \mathcal{M}_j = \{ i \in \{1, \dots, n\} : x_{ij} \text{ is missing} \} \) — the indices with missing entries,
and \( \mathcal{O}_j = \{1, \dots, n\} \setminus \mathcal{M}_j \) — the indices with observed entries.

The objective is to impute all missing values in \( \mathbf{X} \) using an iterative, non-parametric regression/classification scheme based on Random Forests.

---

### Initialization

Let \( \mathbf{X}^{(0)} \) be the initial imputed matrix, constructed by applying:
- Mean imputation for continuous variables,
- Mode imputation for categorical variables.

This serves as the starting point for the iterative procedure.

---

### Iterative Imputation Scheme

For each iteration \( t = 1, 2, \dots \), the following steps are performed:

1. Determine a variable ordering from least to most missing values.
2. For each variable \( j \in \{1, \dots, p\} \):
   - Define:
     \[
     \mathbf{Y}_j = \left( x_{ij} \right)_{i \in \mathcal{O}_j}, \quad
     \mathbf{Z}_j = \left( \mathbf{x}_{i, -j}^{(t-1)} \right)_{i \in \mathcal{O}_j}
     \]
   - Train a Random Forest model \( \hat{f}_j^{(t)} \) using observed data \( (\mathbf{Z}_j, \mathbf{Y}_j) \).
   - Predict missing entries for \( i \in \mathcal{M}_j \) via:
     \[
     \hat{x}_{ij}^{(t)} = \hat{f}_j^{(t)} \left( \mathbf{x}_{i, -j}^{(t-1)} \right)
     \]
3. Replace the missing entries in variable \( j \) with \( \hat{x}_{ij}^{(t)} \) and proceed to the next variable.

After all variables have been processed, the updated matrix \( \mathbf{X}^{(t)} \) is used in the next iteration.

---

### Stopping Criterion

To determine convergence, the algorithm computes the change in imputed values between iterations \( t \) and \( t-1 \), separately for continuous and categorical variables.

- For continuous variables \( \mathcal{N} \):

\[
\Delta_{\mathcal{N}}^{(t)} = \frac{ \sum_{j \in \mathcal{N}} \left\| \mathbf{X}_j^{(t)} - \mathbf{X}_j^{(t-1)} \right\|^2 }
{ \sum_{j \in \mathcal{N}} \left\| \mathbf{X}_j^{(t)} \right\|^2 }
\]

- For categorical variables \( \mathcal{F} \):

\[
\Delta_{\mathcal{F}}^{(t)} = \frac{ \sum_{j \in \mathcal{F}} \sum_{i \in \mathcal{M}_j} \mathbb{I} \left( x_{ij}^{(t)} \ne x_{ij}^{(t-1)} \right) }{ \sum_{j \in \mathcal{F}} |\mathcal{M}_j| }
\]

The algorithm stops when either \( \Delta_{\mathcal{N}}^{(t)} \) or \( \Delta_{\mathcal{F}}^{(t)} \) increases compared to the previous iteration.

---

### Evaluation Metric

To assess imputation performance, the **Normalized Root Mean Squared Error (NRMSE)**[@oba2003bayesian] is used for continuous variables:

\[
\text{NRMSE} = \sqrt{ \frac{ \text{mean} \left( \left( \mathbf{X}_{\text{true}} - \mathbf{X}_{\text{imp}} \right)^2 \right) }{ \text{var} \left( \mathbf{X}_{\text{true}} \right) } }
\]

This is computed only over entries that were originally missing. A lower NRMSE indicates better imputation accuracy, and it provides a scale-invariant comparison between methods and datasets.

# Applications 
## Continuous Variables only

We look at continuous variables first. The two data sets below are obtained from Kaggle.

- **FitBit Fitness Tracker Data**: this dataset includes \( P = 13 \) variables measured across \( n = 940 \) observations from wearable fitness devices. The data combines daily activity records, sleep duration, hourly intensity levels, and second-level heart rate readings. It was obtained from Kaggle and constructed by merging four selected files from the original FitBit collection. For more details on this dataset, see **[FitBit Fitness Tracker Data](https://www.kaggle.com/datasets/arashnic/fitbit/data)**.
- **[Student Habits vs Academic Performance](https://www.kaggle.com/datasets/jayaantanaath/student-habits-vs-academic-performance/data)**: this simulated dataset includes \( P = 16 \) variables measured across \( n = 1,000 \) observations. Each row represents a student and captures daily lifestyle habits such as study hours, sleep duration, social media usage, diet quality, and mental health rating, alongside their final exam score. Only the continuous variables are selected for this section.


```{r, message=FALSE, warning=FALSE}
library(readr)
Habit <- read.csv("Datasets/Student_Habits.csv") #reading data
Habit <- Habit[, -c(1,3,7,10,12,13,15)] #removing all categorical variables
head(Habit)
Fitbit <- read.csv("Datasets/dailyActivity_merged.csv")
Fitbit <- Fitbit[,-c(1,2)]
head(Fitbit)

```
## Fitbit Data
We write a function that generates versions of a dataset with 10%, 20%, and 30% missing values by applying the `produce_NA()` function at each level and store the results in a list. We also write a function to compute the NRMSE.

```{r}
dat_missing <- function(data) {
  missingLevels <- c(0.1, 0.2, 0.3)
  missing_datasets <- list()
  
  for (i in missingLevels) {
    data_missing <- produce_NA(data, proportion = i)
    
    missing_datasets[[paste0("missing_", i * 100)]] <- data_missing
  }
  
  return(missing_datasets)
}

# Normalized Root Mean Squared Error
nrmse <- function(imputed, original, mask) {
  sqrt(mean((imputed[mask] - original[mask])^2)) / sd(original[mask])
}
```
The codes below compare the imputation performance of **KNN** and **missForest** across 100 repetitions and 3 levels of missingness (10%, 20%, 30%). For each repetition, it introduces missing values using `dat_missing()`, imputes them using both methods, and stores the Normalized Root Mean Squared Error (NRMSE) results in a list.

```{r, message=FALSE, warning=FALSE}
library(VIM)
library(missForest)
library(missForestPredict)
set.seed(2025)
reps <- 100
missingLevels <- c(0.1, 0.2, 0.3)
methods <- c("KNN", "missForest")

results_list <- list()

for (level in missingLevels) {
  
  rep_results <- matrix(NA, nrow = reps, ncol = length(methods))
  colnames(rep_results) <- methods
  
  for (r in 1:reps) {
    
    # Generate  NAs
    data_missing_list <- dat_missing(Fitbit)
    data_miss <- data_missing_list[[paste0("missing_", level * 100)]]
    mask <- is.na(data_miss)
    
    # KNN
    knn_out <- kNN(data_miss, k = ncol(data_miss)/2)
    # get imputed data
    knn_imp <- knn_out[, 1:13]
    rep_results[r, "KNN"] <- nrmse(knn_imp,Fitbit,is.na(data_miss))
    
    # missForest
    mf_try <- missForest(data_miss, verbose = F)
      rep_results[r, "missForest"] <-nrmse(mf_try$ximp,Fitbit,mask)
  }
  results_list[[paste0("missing_", level * 100)]] <- rep_results
}

```

The code below, finally compares the imputation performance of **KNN** and **missForest** across the three levels of missingness (10%, 20%, and 30%) using the average Normalized Root Mean Squared Error (**NRMSE**) from repeated simulations (100). For each method and missingness level, it computes the mean NRMSE and standard error, then performs a paired Wilcoxon signed-rank test to evaluate whether the difference in performance is statistically significant. If missForest outperforms KNN, asterisks (‘*’, ‘**’, ‘***’) are added to indicate significance at the 0.05, 0.01, and 0.001 levels, respectively. If KNN performs better, hash symbols (‘#’, ‘##’, ‘###’) are used instead. The results are stored in a summary table for interpretation and visualization.

```{r}
summary_df <- data.frame()

for (name in names(results_list)) {
  res <- results_list[[name]]
  level <- gsub("missing_", "", name)
  
  for (method in methods) {
    method_data <- res[, method]
    method_data <- method_data[!is.na(method_data)]
    
    avg <- mean(method_data)
    se <- sd(method_data) / sqrt(length(method_data))
    
    summary_df <- rbind(summary_df, data.frame(
      MissingLevel = paste0(level, "%"),
      Method = method,
      MeanNRMSE = round(avg, 5),
      SE = round(se, 5)
    ))
  }
}

summary_df$Signif <- ""

for (lvl in unique(summary_df$MissingLevel)) {
  res <- results_list[[paste0("missing_", gsub("%", "", lvl))]]
  
  # KNN vs missForest
  if (all(!is.na(res[, "KNN"])) && all(!is.na(res[, "missForest"]))) {
    p_knn <- wilcox.test(res[, "missForest"], res[, "KNN"], paired = TRUE)$p.value
    summary_df$Signif[summary_df$MissingLevel == lvl & summary_df$Method == "KNN"] <- 
      if (mean(res[, "KNN"]) > mean(res[, "missForest"])) {
        if (p_knn < 0.001) "###" else if (p_knn < 0.01) "##" else if (p_knn < 0.05) "#" else ""
      } else {
        if (p_knn < 0.001) "***" else if (p_knn < 0.01) "**" else if (p_knn < 0.05) "*" else ""
      }
  }
}

print(summary_df)
```
Across all three levels of missingness (10%, 20%, and 30%), **missForest consistently outperforms KNN** in terms of imputation accuracy, as measured by the Normalized Root Mean Squared Error (**NRMSE**). At 10% missingness, the average NRMSE for missForest is 0.09696, compared to 0.30411 for KNN. As the level of missing data increases, the performance gap widens: at 20%, missForest achieves 0.10498 while KNN reaches 0.40751; and at 30%, missForest records 0.12153 versus 0.47084 for KNN. Paired Wilcoxon signed-rank tests were performed to assess the statistical significance of these differences. The results indicate that **KNN performs significantly worse than missForest at every level**, with p-values less than 0.001, denoted by the `###` symbol. This consistent and statistically significant advantage demonstrates that **missForest is not only more accurate but also more robust** to increasing amounts of missing data.


## Habit Dataset

```{r}
results_list2 <- list()

for (level in missingLevels) {
  
  rep_results <- matrix(NA, nrow = reps, ncol = length(methods))
  colnames(rep_results) <- methods
  
  for (r in 1:reps) {
    
    # Generate  NAs
    data_missing_list <- dat_missing(Habit)
    data_miss <- data_missing_list[[paste0("missing_", level * 100)]]
    mask <- is.na(data_miss)
    
    # KNN
    knn_out <- kNN(data_miss, k = 5)
    # get imputed data
    knn_imp <- knn_out[, 1:9]
    rep_results[r, "KNN"] <- nrmse(knn_imp,Habit,is.na(data_miss))
    
    # missForest
    mf_try <- missForest(data_miss, verbose = F)
      rep_results[r, "missForest"] <-nrmse(mf_try$ximp,Habit,mask)
  }
  results_list2[[paste0("missing_", level * 100)]] <- rep_results
}

summary_df2 <- data.frame()

for (name in names(results_list2)) {
  res <- results_list2[[name]]
  level <- gsub("missing_", "", name)
  
  for (method in methods) {
    method_data <- res[, method]
    method_data <- method_data[!is.na(method_data)]
    
    avg <- mean(method_data)
    se <- sd(method_data) / sqrt(length(method_data))
    
    summary_df2 <- rbind(summary_df2, data.frame(
      MissingLevel = paste0(level, "%"),
      Method = method,
      MeanNRMSE = round(avg, 5),
      SE = round(se, 5)
    ))
  }
}

summary_df2$Signif <- ""

for (lvl in unique(summary_df2$MissingLevel)) {
  res <- results_list2[[paste0("missing_", gsub("%", "", lvl))]]
  
  # KNN vs missForest
  if (all(!is.na(res[, "KNN"])) && all(!is.na(res[, "missForest"]))) {
    p_knn <- wilcox.test(res[, "missForest"], res[, "KNN"], paired = TRUE)$p.value
    summary_df2$Signif[summary_df2$MissingLevel == lvl & summary_df2$Method == "KNN"] <- 
      if (mean(res[, "KNN"]) > mean(res[, "missForest"])) {
        if (p_knn < 0.001) "###" else if (p_knn < 0.01) "##" else if (p_knn < 0.05) "#" else ""
      } else {
        if (p_knn < 0.001) "***" else if (p_knn < 0.01) "**" else if (p_knn < 0.05) "*" else ""
      }
  }
}

print(summary_df2)
```
For the **Student Habits vs Academic Performance** dataset, missForest again consistently outperforms KNN across all three missingness levels (10%, 20%, and 30%) in terms of lower Normalized Root Mean Squared Error (NRMSE). At 10% missingness, missForest achieves an average NRMSE of 0.15086, compared to 0.18508 for KNN. This performance gap remains stable as missingness increases: at 20%, missForest records 0.16474 while KNN rises to 0.19712, and at 30%, missForest reaches 0.17642 compared to 0.20646 for KNN.

Paired Wilcoxon signed-rank tests show that the differences are **highly statistically significant** at every level of missingness, as indicated by the `###` symbols for KNN (corresponding to \( p < 0.001 \)). These results confirm that missForest provides a more accurate and statistically robust imputation approach than KNN for this dataset, even as the proportion of missing data increases.


#References