---
title: "Imputing Missing Values: Random Forest vs K-Nearest Neighbors"
author: Robert Adongo  
date: "June 7, 2025"
output:
  # cleanrmd::html_document_clean:
  #   theme: NULL
  #   toc: true
  #   toc_float: true
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    number_sections: true
    theme: flatly
    highlight: tango
    df_print: paged
    #css: "custom.css"
bibliography: references.bib
csl: apa.csl
link-citations: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction
## Motivation and Goals 
Missing data poses a significant barrier to effective analysis in many applied research domains. The K-Nearest Neighbors (KNN) method is a simple and widely used imputation technique [@troyanskaya2001missing]. In this project, we implement the `kNN` function from the `VIM` package, which is based on a variation of the Gower distance. This approach is suitable for handling numerical, categorical, ordered, and semi-continuous variables [@kowarik2016imputation].

We also utilize Random Forest (RF), a non-parametric ensemble method, for imputation. Specifically, we employ the `missForest` function from the `missForestPredict` package [@troyanskaya2001missing; @van2011mice; @stekhoven2012missforest; @wright2017ranger].

The goal of this document is to provide a theoretical background for the two imputation methods mentioned above, apply them to datasets with different structures and missingness patterns, and compare their performance.

## The `KNN` Function
<pre> kNN(
  data,
  variable = colnames(data),
  metric = NULL,
  k = 5,
  dist_var = colnames(data),
  weights = NULL,
  numFun = median,
  catFun = maxCat,
  makeNA = NULL,
  NAcond = NULL,
  impNA = TRUE,
  donorcond = NULL,
  mixed = vector(),
  mixed.constant = NULL,
  trace = FALSE,
  imp_var = TRUE,
  imp_suffix = "imp",
  addRF = FALSE,
  onlyRF = FALSE,
  addRandom = FALSE,
  useImputedDist = TRUE,
  weightDist = FALSE,
  methodStand = "range",
  ordFun = medianSamp
)</pre>

## The `missForest` Function
<pre> missForest(
  xmis,
  maxiter = 10,
  fixed_maxiter = FALSE,
  var_weights = NULL,
  decreasing = FALSE,
  initialization = "mean/mode",
  x_init = NULL,
  class.weights = NULL,
  return_integer_as_integer = FALSE,
  save_models = TRUE,
  predictor_matrix = NULL,
  proportion_usable_cases = c(1, 0),
  verbose = TRUE,
  convergence_error = "OOB",
  ...
)</pre>

# Mathematical Setup
## K Nearest Neighbor Imputation

### Model Form
The mathematical setup presented in this section is based on the work by Kowarik and Templ [@kowarik2016imputation], who provide a comprehensive formulation of k-nearest neighbor imputation as implemented in the `VIM` package.

Suppose we observe a data set with missing values. Let \( \mathbf{x}_i = (x_{i1}, x_{i2}, \dots, x_{ip}) \) represent the observed values for observation \( i \) across \( p \) variables, where some entries in \( \mathbf{x}_i \) may be missing.

The goal of k-nearest neighbor (kNN) imputation is to fill in the missing entries of \( \mathbf{x}_i \) using information from the **k most similar (complete) observations**.

Similarity between two observations \( \mathbf{x}_i \) and \( \mathbf{x}_j \) is measured by a **generalized Gower distance**, which is defined to accommodate numerical, categorical, ordinal, binary, and semi-continuous variables [@gower1971general].

### Generalized Gower Distance

Let \( d_{ij} \) denote the distance between observations \( i \) and \( j \). Then:

\[
d_{ij} = \frac{\sum_{k=1}^p w_k \delta_{ijk}}{\sum_{k=1}^p w_k}
\]

where:
 \( w_k \geq 0 \) is the weight assigned to variable \( k \),
 \( \delta_{ijk} \in [0, 1] \) measures the contribution of variable \( k \) to the overall distance between \( i \) and \( j \).

The form of \( \delta_{ijk} \) depends on the type of variable \( k \):

- **Continuous variables**:

\[
\delta_{ijk} = \frac{|x_{ik} - x_{jk}|}{r_k}, \quad \text{where } r_k = \max(x_{\cdot k}) - \min(x_{\cdot k})
\]

- **Ordinal variables** (converted to integers):

\[
\delta_{ijk} = \frac{|x_{ik} - x_{jk}|}{r_k}
\]

- **Nominal or binary variables**:

\[
\delta_{ijk} =
\begin{cases}
0, & \text{if } x_{ik} = x_{jk} \\
1, & \text{otherwise}
\end{cases}
\]

- **Semi-continuous variables** (e.g., income with many zeros):

\[
\delta_{ijk} =
\begin{cases}
0, & \text{if } x_{ik} = s_k \text{ and } x_{jk} = s_k \\
1, & \text{if exactly one of } x_{ik}, x_{jk} \text{ equals } s_k \\
\frac{|x_{ik} - x_{jk}|}{r_k}, & \text{if } x_{ik} \neq s_k \text{ and } x_{jk} \neq s_k
\end{cases}
\]

Here, \( s_k \) is the “special” value (typically zero) where the variable has mass.

### Aggregation Rule

Once the distances \( d_{ij} \) are computed, the **k nearest neighbors** of observation \( i \) (with complete data) are identified. The missing entries of \( \mathbf{x}_i \) are then imputed using an aggregation of the corresponding values from its neighbors:

- For **continuous variables**:

\[
\hat{x}_{ik} = \text{median}\left\{x_{jk} : j \in \mathcal{N}_k(i) \right\}
\]

- For **categorical variables**:

\[
\hat{x}_{ik} = \text{mode}\left\{x_{jk} : j \in \mathcal{N}_k(i) \right\}
\]

where \( \mathcal{N}_k(i) \) denotes the set of indices of the k nearest neighbors for observation \( i \) (based on distance in selected variables).

### Tuning Parameter \( k \)

The parameter \( k \in \mathbb{N} \) controls the number of nearest neighbors used in imputation. Small values of \( k \) may lead to high variance; large values may oversmooth or dilute local structure.

## Random Forest Imputation

The Random Forest-based imputation approach used in this study is based on the missForest algorithm introduced by Stekhoven and Bühlmann [@stekhoven2012missforest]. This method uses iterative, variable-wise Random Forest models to estimate missing entries in a mixed-type data matrix without relying on parametric assumptions.

---

### Data Structure and Objective

Let \( \mathbf{X} = (x_{ij}) \in \mathbb{R}^{n \times p} \) denote a data matrix with \( n \) observations and \( p \) variables. Some entries in \( \mathbf{X} \) are missing.

For each variable \( j \in \{1, \dots, p\} \), define
\( \mathcal{M}_j = \{ i \in \{1, \dots, n\} : x_{ij} \text{ is missing} \} \) — the indices with missing entries,
and \( \mathcal{O}_j = \{1, \dots, n\} \setminus \mathcal{M}_j \) — the indices with observed entries.

The objective is to impute all missing values in \( \mathbf{X} \) using an iterative, non-parametric regression/classification scheme based on Random Forests.

---

### Initialization

Let \( \mathbf{X}^{(0)} \) be the initial imputed matrix, constructed by applying:
- Mean imputation for continuous variables,
- Mode imputation for categorical variables.

This serves as the starting point for the iterative procedure.

---

### Iterative Imputation Scheme

For each iteration \( t = 1, 2, \dots \), the following steps are performed:

1. Determine a variable ordering from least to most missing values.
2. For each variable \( j \in \{1, \dots, p\} \):
   - Define:
     \[
     \mathbf{Y}_j = \left( x_{ij} \right)_{i \in \mathcal{O}_j}, \quad
     \mathbf{Z}_j = \left( \mathbf{x}_{i, -j}^{(t-1)} \right)_{i \in \mathcal{O}_j}
     \]
   - Train a Random Forest model \( \hat{f}_j^{(t)} \) using observed data \( (\mathbf{Z}_j, \mathbf{Y}_j) \).
   - Predict missing entries for \( i \in \mathcal{M}_j \) via:
     \[
     \hat{x}_{ij}^{(t)} = \hat{f}_j^{(t)} \left( \mathbf{x}_{i, -j}^{(t-1)} \right)
     \]
3. Replace the missing entries in variable \( j \) with \( \hat{x}_{ij}^{(t)} \) and proceed to the next variable.

After all variables have been processed, the updated matrix \( \mathbf{X}^{(t)} \) is used in the next iteration.

---

### Stopping Criterion

To determine convergence, the algorithm computes the change in imputed values between iterations \( t \) and \( t-1 \), separately for continuous and categorical variables.

- For continuous variables \( \mathcal{N} \):

\[
\Delta_{\mathcal{N}}^{(t)} = \frac{ \sum_{j \in \mathcal{N}} \left\| \mathbf{X}_j^{(t)} - \mathbf{X}_j^{(t-1)} \right\|^2 }
{ \sum_{j \in \mathcal{N}} \left\| \mathbf{X}_j^{(t)} \right\|^2 }
\]

- For categorical variables \( \mathcal{F} \):

\[
\Delta_{\mathcal{F}}^{(t)} = \frac{ \sum_{j \in \mathcal{F}} \sum_{i \in \mathcal{M}_j} \mathbb{I} \left( x_{ij}^{(t)} \ne x_{ij}^{(t-1)} \right) }{ \sum_{j \in \mathcal{F}} |\mathcal{M}_j| }
\]

The algorithm stops when either \( \Delta_{\mathcal{N}}^{(t)} \) or \( \Delta_{\mathcal{F}}^{(t)} \) increases compared to the previous iteration.

---

### Evaluation Metric

To assess imputation performance, the **Normalized Root Mean Squared Error (NRMSE)**[@oba2003bayesian] is used for continuous variables:

\[
\text{NRMSE} = \sqrt{ \frac{ \text{mean} \left( \left( \mathbf{X}_{\text{true}} - \mathbf{X}_{\text{imp}} \right)^2 \right) }{ \text{var} \left( \mathbf{X}_{\text{true}} \right) } }
\]

This is computed only over entries that were originally missing. A lower NRMSE indicates better imputation accuracy, and it provides a scale-invariant comparison between methods and datasets.

# Applications 
## Continuous Variables only

We begin by focusing on continuous variables, using two datasets obtained from Kaggle.

- **FitBit Fitness Tracker Data**: this dataset includes \( P = 13 \) variables measured across \( n = 940 \) observations from wearable fitness devices. The data combines daily activity records, sleep duration, hourly intensity levels, and second-level heart rate readings. It was obtained from Kaggle and constructed by merging four selected files from the original FitBit collection. For more details on this dataset, see **[FitBit Fitness Tracker Data](https://www.kaggle.com/datasets/arashnic/fitbit/data)**.
- **[Student Habits vs Academic Performance](https://www.kaggle.com/datasets/jayaantanaath/student-habits-vs-academic-performance/data)**: this simulated dataset includes \( P = 16 \) variables measured across \( n = 1,000 \) observations. Each row represents a student and captures daily lifestyle habits such as study hours, sleep duration, social media usage, diet quality, and mental health rating, alongside their final exam score. Only the continuous variables are selected for this section.


```{r, message=FALSE, warning=FALSE}
library(readr)
Habit <- read.csv("Datasets/Student_Habits.csv") #reading data
cols_to_factor <- c(3, 7, 10,12, 13, 15)
Habit[cols_to_factor] <- lapply(Habit[cols_to_factor], as.factor)

Habit_Cont <- Habit[, -c(1,3,7,10,12,13,15)] #removing all categorical variables

head(Habit_Cont)
Fitbit <- read.csv("Datasets/dailyActivity_merged.csv")

Fitbit_Cont <- Fitbit[,-c(1,2)]
head(Fitbit_Cont)

```

## Fitbit Data
We define a function that creates versions of a dataset with 10%, 20%, and 30% missing values using the `produce_NA()` function. These are stored in a list for later use. We also define a function to compute the Normalized Root Mean Squared Error (NRMSE).


```{r}
dat_missing <- function(data) {
  missingLevels <- c(0.1, 0.2, 0.3)
  missing_datasets <- list()
  
  for (i in missingLevels) {
    data_missing <- produce_NA(data, proportion = i)
    
    missing_datasets[[paste0("missing_", i * 100)]] <- data_missing
  }
  
  return(missing_datasets)
}

# Normalized Root Mean Squared Error
nrmse <- function(imputed, original, mask) {
  sqrt(mean((imputed[mask] - original[mask])^2)) / sd(original[mask])
}
```
The codes below compare the imputation performance of **KNN** and **missForest** across 50 repetitions and 3 levels of missingness (10%, 20%, 30%). For each repetition, it introduces missing values using `dat_missing()`, imputes them using both methods, and stores the Normalized Root Mean Squared Error (NRMSE) results in a list.

```{r load-results, message=FALSE, warning=FALSE}
results_list <- readRDS("results/results_fitbit_cont.rds")
results_list2 <- readRDS("results/results_habit_cont.rds")
results_list3 <- readRDS("results/results_habit_mixed.rds")
results_list_cat <- readRDS("results/results_habit_cat.rds")
```

```{r, message=FALSE, warning=FALSE}
# library(VIM)
# library(missForest)
# library(missForestPredict)
# set.seed(2025)
# reps <- 50
# missingLevels <- c(0.1, 0.2, 0.3)
 methods <- c("KNN", "missForest")
# 
# results_list <- list()
# 
# for (level in missingLevels) {
#   
#   rep_results <- matrix(NA, nrow = reps, ncol = length(methods))
#   colnames(rep_results) <- methods
#   
#   for (r in 1:reps) {
#     set.seed(2025 + r + level * 1000)
#     # Generate  NAs
#     data_missing_list <- dat_missing(Fitbit_Cont)
#     data_miss <- data_missing_list[[paste0("missing_", level * 100)]]
#     mask <- is.na(data_miss)
#     
#     # KNN
#     knn_out <- kNN(data_miss, k = ncol(data_miss)/2)
#     # get imputed data
#     knn_imp <- knn_out[, 1:13]
#     rep_results[r, "KNN"] <- nrmse(knn_imp,Fitbit_Cont,is.na(data_miss))
#     
#     # missForest
#     mf_try <- missForest(data_miss, verbose = F)
#       rep_results[r, "missForest"] <-nrmse(mf_try$ximp,Fitbit_Cont,mask)
#   }
#   results_list[[paste0("missing_", level * 100)]] <- rep_results
# }
# saveRDS(results_list, "results/results_fitbit_cont.rds")

```

The code below, finally compares the imputation performance of **KNN** and **missForest** across the three levels of missingness (10%, 20%, and 30%) using the average Normalized Root Mean Squared Error (**NRMSE**) from repeated simulations (100). For each method and missingness level, it computes the mean NRMSE and standard error, then performs a paired Wilcoxon signed-rank test to evaluate whether the difference in performance is statistically significant. If KNN outperforms missForest, asterisks (‘*’, ‘**’, ‘***’) are added to indicate significance at the 0.05, 0.01, and 0.001 levels, respectively. If missForest performs better, hash symbols (‘#’, ‘##’, ‘###’) are used instead. The results are stored in a summary table.

```{r message=FALSE, warning=FALSE}
summary_df <- data.frame()

for (name in names(results_list)) {
  res <- results_list[[name]]
  level <- gsub("missing_", "", name)
  
  for (method in methods) {
    method_data <- res[, method]
    method_data <- method_data[!is.na(method_data)]
    
    avg <- mean(method_data)
    se <- sd(method_data) / sqrt(length(method_data))
    
    summary_df <- rbind(summary_df, data.frame(
      MissingLevel = paste0(level, "%"),
      Method = method,
      MeanNRMSE = round(avg, 5),
      SE = round(se, 5)
    ))
  }
}

summary_df$Signif <- ""

for (lvl in unique(summary_df$MissingLevel)) {
  res <- results_list[[paste0("missing_", gsub("%", "", lvl))]]
  
  # KNN vs missForest
  if (all(!is.na(res[, "KNN"])) && all(!is.na(res[, "missForest"]))) {
    p_knn <- wilcox.test(res[, "missForest"], res[, "KNN"], paired = TRUE)$p.value
    summary_df$Signif[summary_df$MissingLevel == lvl & summary_df$Method == "KNN"] <- 
      if (mean(res[, "KNN"]) > mean(res[, "missForest"])) {
        if (p_knn < 0.001) "###" else if (p_knn < 0.01) "##" else if (p_knn < 0.05) "#" else ""
      } else {
        if (p_knn < 0.001) "***" else if (p_knn < 0.01) "**" else if (p_knn < 0.05) "*" else ""
      }
  }
}

print(summary_df)
```
Across all three levels of missingness (10%, 20%, and 30%), **missForest consistently outperforms KNN** in terms of imputation accuracy, as measured by the **Normalized Root Mean Squared Error (NRMSE)**. At 10% missingness, missForest achieves an average NRMSE of **0.10325**, while KNN yields a much higher value of **0.29998**. This trend continues as the proportion of missing data increases: at 20%, missForest maintains a low error of **0.10535** compared to **0.39477** for KNN; and at 30%, missForest records **0.12409**, whereas KNN rises to **0.46118**.

Paired **Wilcoxon signed-rank tests** reveal that these differences are **highly statistically significant** at every level of missingness, with **p-values less than 0.001**, denoted by the `###` symbols next to KNN. These results highlight that **missForest is not only more accurate but also more robust** than KNN as the amount of missing data increases.



## Habit Dataset

```{r message=FALSE, warning=FALSE}
# results_list2 <- list()
# 
# for (level in missingLevels) {
#   
#   rep_results <- matrix(NA, nrow = reps, ncol = length(methods))
#   colnames(rep_results) <- methods
#   
#   for (r in 1:reps) {
#     
#     # Generate  NAs
#     data_missing_list <- dat_missing(Habit_Cont)
#     data_miss <- data_missing_list[[paste0("missing_", level * 100)]]
#     mask <- is.na(data_miss)
#     
#     # KNN
#     knn_out <- kNN(data_miss, k = 5)
#     # get imputed data
#     knn_imp <- knn_out[, 1:9]
#     rep_results[r, "KNN"] <- nrmse(knn_imp,Habit_Cont,is.na(data_miss))
#     
#     # missForest
#     mf_try <- missForest(data_miss, verbose = F)
#       rep_results[r, "missForest"] <-nrmse(mf_try$ximp,Habit_Cont,mask)
#   }
#   results_list2[[paste0("missing_", level * 100)]] <- rep_results
# }
# 
# saveRDS(results_list2, "results/results_habit_cont.rds")
summary_df2 <- data.frame()

for (name in names(results_list2)) {
  res <- results_list2[[name]]
  level <- gsub("missing_", "", name)
  
  for (method in methods) {
    method_data <- res[, method]
    method_data <- method_data[!is.na(method_data)]
    
    avg <- mean(method_data)
    se <- sd(method_data) / sqrt(length(method_data))
    
    summary_df2 <- rbind(summary_df2, data.frame(
      MissingLevel = paste0(level, "%"),
      Method = method,
      MeanNRMSE = round(avg, 5),
      SE = round(se, 5)
    ))
  }
}

summary_df2$Signif <- ""

for (lvl in unique(summary_df2$MissingLevel)) {
  res <- results_list2[[paste0("missing_", gsub("%", "", lvl))]]
  
  # KNN vs missForest
  if (all(!is.na(res[, "KNN"])) && all(!is.na(res[, "missForest"]))) {
    p_knn <- wilcox.test(res[, "missForest"], res[, "KNN"], paired = TRUE)$p.value
    summary_df2$Signif[summary_df2$MissingLevel == lvl & summary_df2$Method == "KNN"] <- 
      if (mean(res[, "KNN"]) > mean(res[, "missForest"])) {
        if (p_knn < 0.001) "###" else if (p_knn < 0.01) "##" else if (p_knn < 0.05) "#" else ""
      } else {
        if (p_knn < 0.001) "***" else if (p_knn < 0.01) "**" else if (p_knn < 0.05) "*" else ""
      }
  }
}

print(summary_df2)
```
For the **Student Habits vs Academic Performance** dataset, **missForest again consistently outperforms KNN** across all three missingness levels (10%, 20%, and 30%) in terms of lower **Normalized Root Mean Squared Error (NRMSE)**. At 10% missingness, missForest achieves an average NRMSE of **0.15049**, compared to **0.18503** for KNN. As the missingness increases, the performance gap remains evident: at 20%, missForest records **0.16332**, while KNN rises to **0.19550**; and at 30%, missForest reaches **0.17681**, compared to **0.20758** for KNN.

Paired **Wilcoxon signed-rank tests** show that the differences are **highly statistically significant** at every level of missingness, as indicated by the `###` symbols for KNN (corresponding to \( p < 0.001 \)). These results confirm that **missForest provides a more accurate and statistically robust imputation approach than KNN** for this dataset, even as the proportion of missing data increases.


## Mixed-type data 
The same data set Habit is used with the categorical variables included.

```{r message=FALSE, warning=FALSE}
Habit_Mixed <- Habit[,-1]

cont_vars <- sapply(Habit_Mixed, is.numeric)
cat_vars <- sapply(Habit_Mixed, is.factor)

# Initialize results list
# results_list3 <- list()
# for (level in missingLevels) {
#   rep_results <- matrix(NA, nrow = reps, ncol = length(methods) * 2)  # NRMSE + PFC per method
#   colnames(rep_results) <- c("KNN_NRMSE", "KNN_PFC", "missForest_NRMSE", "missForest_PFC")
#   
#   for (r in 1:reps) {
#     # Generate missing data
#     data_missing_list <- dat_missing(Habit_Mixed)
#     data_miss <- data_missing_list[[paste0("missing_", level * 100)]]
#     mask <- is.na(data_miss)
#     
#     # --- KNN ---
#     knn_out <- kNN(data_miss, k = 5)
#     knn_imp <- knn_out[, 1:15]  # Ensure proper column names
# 
#     rep_results[r, "KNN_NRMSE"] <- nrmse(
#       knn_imp[, cont_vars], Habit_Mixed[, cont_vars], is.na(data_miss[, cont_vars])
#     )
#     rep_results[r, "KNN_PFC"] <- pfc(
#       knn_imp[, cat_vars], Habit_Mixed[, cat_vars], is.na(data_miss[, cat_vars])
#     )
#     
#     # --- missForest ---
#     mf_out <- missForest(data_miss, verbose = FALSE)
#     mf_imp <- mf_out$ximp
# 
#     rep_results[r, "missForest_NRMSE"] <- nrmse(
#       mf_imp[, cont_vars], Habit_Mixed[, cont_vars], is.na(data_miss[, cont_vars])
#     )
#     rep_results[r, "missForest_PFC"] <- pfc(
#       mf_imp[, cat_vars], Habit_Mixed[, cat_vars], is.na(data_miss[, cat_vars])
#     )
#   }
#   
#   results_list3[[paste0("missing_", level * 100)]] <- rep_results
# }
# 
# saveRDS(results_list3, "results/results_habit_mixed.rds")
summary_df3 <- data.frame()

for (name in names(results_list3)) {
  res <- results_list3[[name]]
  level <- gsub("missing_", "", name)
  
  for (metric in c("NRMSE", "PFC")) {
    for (method in methods) {
      colname <- paste0(method, "_", metric)
      method_data <- res[, colname]
      method_data <- method_data[!is.na(method_data)]
      
      avg <- mean(method_data)
      se <- sd(method_data) / sqrt(length(method_data))
      
      summary_df3 <- rbind(summary_df3, data.frame(
        MissingLevel = paste0(level, "%"),
        Method = method,
        Metric = metric,
        Mean = round(avg, 5),
        SE = round(se, 5),
        Signif = ""
      ))
    }
  }
}

for (lvl in unique(summary_df3$MissingLevel)) {
  res <- results_list3[[paste0("missing_", gsub("%", "", lvl))]]
  
  # NRMSE comparison
  if (all(!is.na(res[, "KNN_NRMSE"])) && all(!is.na(res[, "missForest_NRMSE"]))) {
    p_val <- wilcox.test(res[, "missForest_NRMSE"], res[, "KNN_NRMSE"], paired = TRUE)$p.value
    signif <- if (mean(res[, "KNN_NRMSE"]) > mean(res[, "missForest_NRMSE"])) {
      if (p_val < 0.001) "###" else if (p_val < 0.01) "##" else if (p_val < 0.05) "#" else ""
    } else {
      if (p_val < 0.001) "***" else if (p_val < 0.01) "**" else if (p_val < 0.05) "*" else ""
    }
    summary_df3$Signif[summary_df3$MissingLevel == lvl & summary_df3$Method == "KNN" & summary_df3$Metric == "NRMSE"] <- signif
  }

  # PFC comparison
  if (all(!is.na(res[, "KNN_PFC"])) && all(!is.na(res[, "missForest_PFC"]))) {
    p_val <- wilcox.test(res[, "missForest_PFC"], res[, "KNN_PFC"], paired = TRUE)$p.value
    signif <- if (mean(res[, "KNN_PFC"]) > mean(res[, "missForest_PFC"])) {
      if (p_val < 0.001) "###" else if (p_val < 0.01) "##" else if (p_val < 0.05) "#" else ""
    } else {
      if (p_val < 0.001) "***" else if (p_val < 0.01) "**" else if (p_val < 0.05) "*" else ""
    }
    summary_df3$Signif[summary_df3$MissingLevel == lvl & summary_df3$Method == "KNN" & summary_df3$Metric == "PFC"] <- signif
  }
}

print(summary_df3)

```
For the **mixed-type version** of the *Student Habits vs Academic Performance* dataset, **missForest consistently outperforms KNN** across all three missingness levels (10%, 20%, and 30%) in terms of both imputation accuracy for continuous variables and classification accuracy for categorical variables.

At 10% missingness, missForest achieves an average NRMSE of **0.15207**, while KNN records **0.21567**. We see the similar results for 20% and 30% missingness.

Similarly, for **categorical variables**, evaluated using the **Proportion of Falsely Classified (PFC)** entries, missForest again yields better performance. At 10% missingness, missForest achieves a PFC of **0.47867**, while KNN reaches **0.51540**. This pattern remains consistent at higher missingness levels: missForest maintains lower PFC values of **0.48280** and **0.48004**, compared to **0.51267** and **0.51172** for KNN at 20% and 30%, respectively.

Paired **Wilcoxon signed-rank tests** confirm that these differences are **highly statistically significant** (\( p < 0.001 \)) for both NRMSE and PFC at all levels of missingness, as indicated by the `###` symbols for KNN. These findings demonstrate that **missForest provides a more accurate and reliable imputation strategy** than KNN for this datasets with a mix of variable types, especially as the proportion of missing data increases.


## Categorical Variables Only
With the same data set Habits, we select just the categorical variables. 

```{r message=FALSE, warning=FALSE}
Habit_Cat <- Habit_Mixed[, cat_vars]
# results_list_cat <- list()
# 
# for (level in missingLevels) {
#   rep_results <- matrix(NA, nrow = reps, ncol = length(methods))
#   colnames(rep_results) <- methods
#   
#   for (r in 1:reps) {
#     # Generate missing data
#     data_missing_list <- dat_missing(Habit_Cat)  # replace with your categorical-only dataset
#     data_miss <- data_missing_list[[paste0("missing_", level * 100)]]
#     mask <- is.na(data_miss)
#     
#     # --- KNN ---
#     knn_out <- kNN(data_miss, k = 5)
#     knn_imp <- knn_out[, names(Habit_Cat)]  # retain original structure
#     rep_results[r, "KNN"] <- pfc(knn_imp, Habit_Cat, mask)
#     
#     # --- missForest ---
#     mf_out <- missForest(data_miss, verbose = FALSE)
#     mf_imp <- mf_out$ximp
#     rep_results[r, "missForest"] <- pfc(mf_imp, Habit_Cat, mask)
#   }
#   
#   results_list_cat[[paste0("missing_", level * 100)]] <- rep_results
# }
# 
# saveRDS(results_list_cat, "results/results_habit_cat.rds")
summary_df_cat <- data.frame()

for (name in names(results_list_cat)) {
  res <- results_list_cat[[name]]
  level <- gsub("missing_", "", name)
  
  for (method in methods) {
    method_data <- res[, method]
    method_data <- method_data[!is.na(method_data)]
    
    avg <- mean(method_data)
    se <- sd(method_data) / sqrt(length(method_data))
    
    summary_df_cat <- rbind(summary_df_cat, data.frame(
      MissingLevel = paste0(level, "%"),
      Method = method,
      Metric = "PFC",
      Mean = round(avg, 5),
      SE = round(se, 5),
      Signif = ""
    ))
  }
}

for (lvl in unique(summary_df_cat$MissingLevel)) {
  res <- results_list_cat[[paste0("missing_", gsub("%", "", lvl))]]
  
  if (all(!is.na(res[, "KNN"])) && all(!is.na(res[, "missForest"]))) {
    p_val <- wilcox.test(res[, "missForest"], res[, "KNN"], paired = TRUE)$p.value
    signif <- if (mean(res[, "KNN"]) > mean(res[, "missForest"])) {
      if (p_val < 0.001) "###" else if (p_val < 0.01) "##" else if (p_val < 0.05) "#" else ""
    } else {
      if (p_val < 0.001) "***" else if (p_val < 0.01) "**" else if (p_val < 0.05) "*" else ""
    }
    summary_df_cat$Signif[summary_df_cat$MissingLevel == lvl & summary_df_cat$Method == "KNN"] <- signif
  }
}

print(summary_df_cat)

```

Across all levels of missingness (10%, 20%, and 30%), **missForest outperforms KNN**, consistently yielding lower classification error rates.

At 10% missingness, missForest achieves a PFC of **0.47187**, whereas KNN records a higher value of **0.51663**. As missingness increases, the performance gap persists: at 20%, missForest yields **0.48937**, compared to **0.52158** for KNN; and at 30%, missForest maintains a lower PFC of **0.48987**, while KNN reaches **0.52161**.

These differences are confirmed by paired **Wilcoxon signed-rank tests**, which show **highly statistically significant results** in favor of missForest at every level of missingness (\( p < 0.001 \)), indicated by the `###` symbols for KNN. These results demonstrate that **missForest is more effective and consistent** than KNN when imputing categorical data, particularly as the proportion of missing values increases.



## Conclusion

Across all experiments, **missForest consistently outperformed KNN** in terms of imputation accuracy. It achieved lower NRMSE for continuous variables and lower PFC for categorical variables across all levels of missingness. The differences were statistically significant in nearly all cases. Overall, **missForest proved to be a more reliable and robust method** for handling missing data, especially as missingness increased or when working with mixed data types.


#References